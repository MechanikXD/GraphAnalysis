{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from scipy.linalg import eigh\n",
        "import sys"
      ],
      "metadata": {
        "id": "ysgXGrOsE39u"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_graph_from_csv(filepath):\n",
        "    # Try reading with pandas to auto-detect format\n",
        "    try:\n",
        "        # First, try reading assuming first column is index\n",
        "        df = pd.read_csv(filepath, index_col=0)\n",
        "        # Check if index names match column names (indicates proper format)\n",
        "        if len(df.index) == len(df.columns):\n",
        "            node_names = df.columns.tolist()\n",
        "            data = df.values.astype(float)\n",
        "        else:\n",
        "            raise ValueError(\"Mismatch in dimensions\")\n",
        "    except:\n",
        "        # If that fails, assume no row labels, just matrix with header row\n",
        "        df = pd.read_csv(filepath)\n",
        "        node_names = df.columns.tolist()\n",
        "        data = df.values.astype(float)\n",
        "\n",
        "    n = len(node_names)\n",
        "\n",
        "    # Create weighted graph\n",
        "    G = nx.Graph()\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n):  # Upper triangle only (undirected)\n",
        "            if data[i, j] > 0:\n",
        "                G.add_edge(i, j, weight=data[i, j])\n",
        "\n",
        "    return G, data, node_names\n",
        "\n",
        "def compute_all_metrics(G, data):\n",
        "    \"\"\"Compute all metrics using NetworkX\"\"\"\n",
        "    n = len(G.nodes())\n",
        "    results = {}\n",
        "\n",
        "    print(\"Computing metrics with NetworkX...\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 1. Node Degree (unweighted)\n",
        "    print(\"1. Node Degree (unweighted)...\")\n",
        "    degrees = dict(G.degree())\n",
        "    results['Node Degree'] = [degrees[i] for i in range(n)]\n",
        "\n",
        "    # 2. Clustering Coefficient\n",
        "    print(\"2. Clustering Coefficient...\")\n",
        "    clustering = nx.clustering(G)\n",
        "    results['Clustering Coefficient'] = [clustering[i] for i in range(n)]\n",
        "\n",
        "    # 3. Betweenness Centrality (weighted)\n",
        "    print(\"3. Betweenness Centrality (weighted)...\")\n",
        "    betweenness = nx.betweenness_centrality(G, weight='weight', normalized=True)\n",
        "    results['Betweenness Centrality'] = [betweenness[i] for i in range(n)]\n",
        "\n",
        "    # 4. Eigenvector Centrality (weighted)\n",
        "    print(\"4. Eigenvector Centrality (weighted)...\")\n",
        "    try:\n",
        "        eigenvector = nx.eigenvector_centrality(G, weight='weight', max_iter=1000)\n",
        "        results['Eigenvector Centrality'] = [eigenvector[i] for i in range(n)]\n",
        "    except:\n",
        "        print(\"   WARNING: Eigenvector centrality failed to converge\")\n",
        "        results['Eigenvector Centrality'] = [0.0] * n\n",
        "\n",
        "    # 5. Local Efficiency (weighted)\n",
        "    print(\"5. Local Efficiency (weighted)...\")\n",
        "    local_eff = []\n",
        "    for node in range(n):\n",
        "        neighbors = list(G.neighbors(node))\n",
        "        if len(neighbors) < 2:\n",
        "            local_eff.append(0.0)\n",
        "            continue\n",
        "\n",
        "        # Create subgraph of neighbors\n",
        "        subgraph = G.subgraph(neighbors)\n",
        "\n",
        "        # Compute efficiency among neighbors\n",
        "        total = 0.0\n",
        "        count = 0\n",
        "        for i, u in enumerate(neighbors):\n",
        "            for j, v in enumerate(neighbors):\n",
        "                if i < j:\n",
        "                    try:\n",
        "                        dist = nx.shortest_path_length(subgraph, u, v, weight='weight')\n",
        "                        if dist > 0:\n",
        "                            total += 1.0 / dist\n",
        "                    except nx.NetworkXNoPath:\n",
        "                        pass\n",
        "                    count += 1\n",
        "\n",
        "        local_eff.append(total / count if count > 0 else 0.0)\n",
        "\n",
        "    results['Efficiency'] = local_eff\n",
        "\n",
        "    # 6. Removal Tolerance (largest component size change)\n",
        "    print(\"6. Removal Tolerance...\")\n",
        "    baseline_size = len(max(nx.connected_components(G), key=len))\n",
        "    removal_tolerance = []\n",
        "    for node in range(n):\n",
        "        G_copy = G.copy()\n",
        "        G_copy.remove_node(node)\n",
        "        if len(G_copy.nodes()) > 0:\n",
        "            largest = len(max(nx.connected_components(G_copy), key=len))\n",
        "        else:\n",
        "            largest = 0\n",
        "        removal_tolerance.append(largest - baseline_size)\n",
        "    results['Removal Tolerance'] = removal_tolerance\n",
        "\n",
        "    # 7. Laplacian Spectrum (eigenvalues)\n",
        "    print(\"7. Laplacian Spectrum...\")\n",
        "    # Build weighted Laplacian\n",
        "    degrees_weighted = [sum(data[i, j] for j in range(n) if data[i, j] > 0) for i in range(n)]\n",
        "    D = np.diag(degrees_weighted)\n",
        "    L = D - data\n",
        "    eigenvalues = np.linalg.eigvalsh(L)\n",
        "    eigenvalues = np.abs(eigenvalues)\n",
        "    eigenvalues.sort()\n",
        "    results['Laplacian Spectrum'] = eigenvalues.tolist()\n",
        "\n",
        "    # 8. Graph-level metrics\n",
        "    print(\"8. Graph-level metrics...\")\n",
        "\n",
        "    # Degree Entropy\n",
        "    total_degree = sum(results['Node Degree'])\n",
        "    entropy = 0.0\n",
        "    for deg in results['Node Degree']:\n",
        "        p = deg / total_degree\n",
        "        if p > 0:\n",
        "            entropy -= p * np.log2(p)\n",
        "    results['Entropy'] = entropy\n",
        "\n",
        "    # Degree Assortativity\n",
        "    assortativity = nx.degree_assortativity_coefficient(G)\n",
        "    results['Assortativity'] = assortativity\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"All metrics computed!\\n\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "pyxfOcuwExnm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File paths\n",
        "adjacency_file = '/content/newAdjacencyMatrix.csv'\n",
        "stats_file = '/content/newStats.csv'\n",
        "\n",
        "print(\"Network Metrics Verification Tool\")\n",
        "print(\"Using NetworkX as reference implementation\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "\n",
        "# Load graph\n",
        "print(f\"Loading graph from: {adjacency_file}\")\n",
        "G, data, node_names = load_graph_from_csv(adjacency_file)\n",
        "print(f\"Graph loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "print()\n",
        "\n",
        "# Load C# results\n",
        "print(f\"Loading C# results from: {stats_file}\")\n",
        "csharp_results = pd.read_csv(stats_file, index_col=0)\n",
        "node_names = csharp_results.columns.tolist()\n",
        "print(f\"Loaded {len(csharp_results)} metrics for {len(node_names)} nodes\")\n",
        "print()\n",
        "\n",
        "# Compute NetworkX metrics\n",
        "print(f\"Metrics conmuped by this script:\\n\")\n",
        "print(compute_all_metrics(G, data))"
      ],
      "metadata": {
        "id": "rcKa-jxPFD9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1a6d8a-0678-4bb3-abf2-f9de6066532e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network Metrics Verification Tool\n",
            "Using NetworkX as reference implementation\n",
            "================================================================================\n",
            "\n",
            "Loading graph from: /content/newAdjacencyMatrix.csv\n",
            "Graph loaded: 12 nodes, 22 edges\n",
            "\n",
            "Loading C# results from: /content/newStats.csv\n",
            "Loaded 7 metrics for 12 nodes\n",
            "\n",
            "Metrics conmuped by this script:\n",
            "\n",
            "Computing metrics with NetworkX...\n",
            "================================================================================\n",
            "1. Node Degree (unweighted)...\n",
            "2. Clustering Coefficient...\n",
            "3. Betweenness Centrality (weighted)...\n",
            "4. Eigenvector Centrality (weighted)...\n",
            "5. Local Efficiency (weighted)...\n",
            "6. Removal Tolerance...\n",
            "7. Laplacian Spectrum...\n",
            "8. Graph-level metrics...\n",
            "================================================================================\n",
            "All metrics computed!\n",
            "\n",
            "{'Node Degree': [2, 4, 5, 4, 5, 3, 2, 5, 5, 3, 4, 2], 'Clustering Coefficient': [1.0, 0.6666666666666666, 0.6, 0.8333333333333334, 0.6, 0.6666666666666666, 1.0, 0.3, 0.5, 0.6666666666666666, 0.5, 1.0], 'Betweenness Centrality': [0.0, 0.0, 0.2727272727272727, 0.0, 0.03636363636363636, 0.0, 0.0, 0.5272727272727272, 0.4909090909090909, 0.0, 0.16363636363636364, 0.0], 'Eigenvector Centrality': [np.float64(0.16650480556853633), np.float64(0.34971082275568965), np.float64(0.35765588198210263), np.float64(0.3841064115204993), np.float64(0.38775002699306954), np.float64(0.2645792151773993), np.float64(0.13788913705481157), np.float64(0.28750082421571205), np.float64(0.42571749618484134), np.float64(0.16092772053573565), np.float64(0.18587409276015177), np.float64(0.10401127895086586)], 'Efficiency': [np.float64(0.1071053014339472), np.float64(0.09520414195435145), np.float64(0.06930969460475157), np.float64(0.08869982216359475), np.float64(0.06795086989773676), np.float64(0.07568294821005479), np.float64(0.07965836122039795), np.float64(0.02953800440867065), np.float64(0.07542134021612215), np.float64(0.06395324622183533), np.float64(0.05052212338158248), np.float64(0.0862803836370978)], 'Removal Tolerance': [-1, -1, -1, -1, -1, -1, -1, -5, -1, -1, -1, -1], 'Laplacian Spectrum': [1.854439664587313e-15, 4.225001889859059, 19.641021380480968, 24.11509836500415, 33.77947075155575, 47.116533642660734, 52.34305876257288, 62.590909206648526, 66.71385021123972, 70.31247678335097, 73.96509054182255, 86.3979264648046], 'Entropy': np.float64(3.5060603254083387), 'Assortativity': -0.08196721311475244}\n"
          ]
        }
      ]
    }
  ]
}